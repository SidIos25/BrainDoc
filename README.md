# BrainDoc AI â€” Document Intelligence

Tagline: Unlock Insights from Every Document.

BrainDoc AI is a Streamlit RAG app. Upload PDFs/DOCX/TXT, pick a domain (Healthcare, Legal, Finance, Education), and get contextual answers with source citations. Safety checks block risky queries; chat history is saved between turns.

---

## ðŸš€ Features

| Feature                          | Description                                                                 |
|----------------------------------|-----------------------------------------------------------------------------|
| ðŸ” Domain Selection              | Choose Healthcare, Legal, Finance, or Education                             |
| ðŸ“„ Multi-file Upload             | Upload one or more PDFs, Word Docs, or TXT files                            |
| ðŸ’¬ Contextual Q&A               | Ask specific questions about document content                               |
| ðŸ§  Custom Prompting             | Domain-aware prompts for tailored, relevant answers                         |
| ðŸ’¾ Chat Memory + History        | Stores past interactions between sessions                                   |
| ðŸ“ Sample Reports               | Try included examples in the `samples/` folder                             |
| ðŸ“Ž Source Citations             | Shows the top context chunks used for each answer                           |
| ðŸ“Š Session Metrics              | Sidebar metrics: documents uploaded, chunks indexed, questions asked        |

---

## ðŸ§­ How It Works
1) Upload & parse: User uploads PDF/DOCX/TXT; `file_loader` saves temp files, reads, and chunks text (800 size, 100 overlap) with PDF fallbacks (PyPDF â†’ PDFPlumber â†’ PyMuPDF).
2) Embed & index: `embedder` builds a FAISS vector store from chunks using OpenAI embeddings.
3) Domain-aware prompting: `domain_prompts` picks the prompt for Healthcare/Legal/Finance/Education.
4) Retrieval-augmented Q&A: `qa_chain` retrieves relevant chunks and queries the LLM with domain prompt + question.
5) Safety checks: `app.py` blocks very long or suspect questions before sending to the model.
6) Memory: `memory_manager` trims/saves chat history so answers stay concise across turns.
7) UI loop: Streamlit renders results, shows session metrics, and lets the user continue asking questions.
8) Sources: After answers, a â€œSources Usedâ€ section previews the top context chunks.

High-level flow:

User â†’ Upload files â†’ Parse & chunk â†’ Embed â†’ FAISS search â†’ Domain prompt + question â†’ LLM answers â†’ Store chat history

---

## ðŸ“ Folder Structure

```
BrainDoc/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ chat_history.pkl
â”œâ”€â”€ data/                       # ðŸ“„ Sample documents
â”‚   â”œâ”€â”€ healthcare_sample.txt
â”‚   â”œâ”€â”€ finance_example.txt
â”‚   â”œâ”€â”€ legal_contract.txt
â”‚   â””â”€â”€ course_outline.txt
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ file_loader.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ qa_chain.py
â”‚   â”œâ”€â”€ memory_manager.py
â”‚   â””â”€â”€ domain_prompts.py
â”œâ”€â”€ samples/                        # ðŸ“‹ Domain-specific test documents
â”‚   â”œâ”€â”€ COURSE_SYLLABUS.txt         (Education)
â”‚   â”œâ”€â”€ SOFTWARE_LICENSE_AGREEMENT.txt  (Legal)
â”‚   â”œâ”€â”€ MEDICAL_REPORT.txt          (Healthcare)
â”‚   â””â”€â”€ FINANCIAL_REPORT.txt        (Finance)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_smoke.py
â””â”€â”€ .github/
```

---

## ðŸ§ª Quick Test with Sample Documents
Upload any file from the `samples/` folder to test each domain:

| Domain | Document | Try Asking |
|--------|----------|------------|
| ðŸ¥ Healthcare | `MEDICAL_REPORT.txt` | "What are the critical health risks identified?" |
| âš–ï¸ Legal | `SOFTWARE_LICENSE_AGREEMENT.txt` | "What are the restrictions on the licensee?" |
| ðŸ’¼ Finance | `FINANCIAL_REPORT.txt` | "What were the major revenue sources?" |
| ðŸŽ“ Education | `COURSE_SYLLABUS.txt` | "What are the course objectives?" |

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/braindoc.git
cd BrainDoc
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Create your `.env` from the example**
```
# Windows (PowerShell)
Copy-Item .env.example .env

# macOS/Linux
cp .env.example .env
```
Open `.env` and set your key:
```
OPENAI_API_KEY=your_openai_key_here
```

4. **Run the app**
```bash
streamlit run app.py
```

5. **(Optional) Lock exact versions for reproducibility**
```bash
pip freeze > requirements.lock
```

6. **Run tests locally**
```bash
pytest -q
```

---

## ðŸ“Œ Roadmap Ideas
- Citations with sources
- Per-domain prompt fine-tuning
- PDF highlighting & annotations
- User login & cloud session storage
- Prompt safety: stronger PII/prompt-injection checks
- Evaluation: lightweight answer grading against expectations

---

## ðŸ”’ Security
- Keep secrets out of Git: `.env` is ignored by `.gitignore` (use `.env.example` to share the shape).
- Before pushing, run `git status` to confirm `.env` and `chat_history.pkl` are not staged.

---

## ðŸ“œ License
MIT

---



